{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98539237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from matplotlib import pyplot as plot\n",
    "#from sklearn.linear_model import train_test_split as tts\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    URL_TRAIN = \"https://www.mxhackathon.co.za/docs/TrainData.csv\"\n",
    "\n",
    "    dataframeTrain = pd.read_csv(URL_TRAIN)\n",
    "\n",
    "    #for attribute in dataframeTrain.columns:\n",
    "     #if dataframeTrain[attribute].dtype == object:\n",
    "        #dataframeTrain[attribute] = dataframeTrain[attribute].astype('category')\n",
    "\n",
    "\n",
    "\n",
    "    print(dataframeTrain.describe().T)\n",
    "    #print(dataframeTrain.describe(include = 'category').T)\n",
    "\n",
    "    dataframeTrain.drop(['LeadID'], axis=1, inplace=True)\n",
    "    dataframeTrain.drop(['InFinanceProcessSystemApp'], axis=1, inplace=True)\n",
    "    dataframeTrain.drop(['FinanceApplied'], axis=1, inplace=True)\n",
    "    dataframeTrain.drop(['FinanceApproved'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframeTrain\n",
    "\n",
    "def analyze_missing(dataframeTrain):\n",
    "    missing_summary = dataframeTrain.isnull().sum()\n",
    "    missing_percentage = (missing_summary / len(dataframeTrain)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'MissingCount': missing_summary,\n",
    "        'MissingPercentage': missing_percentage\n",
    "    })\n",
    "    missing_df = missing_df[missing_df['MissingCount'] > 0]\n",
    "    print(\"Missing Value Summary:\")\n",
    "    print(missing_df.sort_values(by='MissingPercentage', ascending=False))\n",
    "\n",
    "def clean_missing_values(dataframeTrain):\n",
    "    # Drop columns with > 50% missing values\n",
    "    threshold = 0.5 * len(dataframeTrain)\n",
    "    dataframeTrain = dataframeTrain.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "    # Drop rows where key fields are missing\n",
    "    required_fields = ['OBSFullName', 'OBSEmail', 'Domain', 'CellPrefix', 'CellPhoneNoLength']\n",
    "    existing_fields = [field for field in required_fields if field in dataframeTrain.columns]\n",
    "\n",
    "    if existing_fields:\n",
    "        dataframeTrain = dataframeTrain.dropna(subset=existing_fields)\n",
    "\n",
    "    # Fill remaining missing values\n",
    "    for col in dataframeTrain.columns:\n",
    "        if dataframeTrain[col].dtype == 'object':\n",
    "            dataframeTrain[col] = dataframeTrain[col].fillna('Unknown')\n",
    "        elif dataframeTrain[col].dtype in ['float64', 'int64']:\n",
    "           dataframeTrain[col] = dataframeTrain[col].fillna(dataframeTrain[col].median())\n",
    "\n",
    "    return dataframeTrain\n",
    "\n",
    "\n",
    "def train_ensemble_model(dataframeTrain):\n",
    "\n",
    "\n",
    "    #===============================\n",
    "    # Step 1: Clean the data\n",
    "    #===============================\n",
    "\n",
    "    # Encoding headers that are of type object since we can train the model using those types\n",
    "    dataframeTrain['CustomerID'] = LabelEncoder().fit_transform(dataframeTrain['CustomerID'])\n",
    "    dataframeTrain['CustomerIDCount'] = dataframeTrain.groupby('CustomerID')['CustomerID'].transform('count') #Using the count rather than id increases PR-AUC\n",
    "\n",
    "    # Count how many leads a dealer handles (popularity or reach of dealer)\n",
    "    dataframeTrain['DealerEnquiryVolume'] = dataframeTrain.groupby('Dealer')['Dealer'].transform('count')\n",
    "\n",
    "\n",
    "    dataframeTrain['DTLeadCreatedEnc'] = LabelEncoder().fit_transform(dataframeTrain['DTLeadCreated'])\n",
    "    dataframeTrain['DTLeadAllocatedEnc'] = LabelEncoder().fit_transform(dataframeTrain['DTLeadAllocated'])\n",
    "    dataframeTrain['DealerEnc'] = LabelEncoder().fit_transform(dataframeTrain['Dealer'])\n",
    "    dataframeTrain['LeadSourceEnc'] = LabelEncoder().fit_transform(dataframeTrain['LeadSource'])\n",
    "    dataframeTrain['LeadTypeEnc'] = LabelEncoder().fit_transform(dataframeTrain['LeadType'])\n",
    "    dataframeTrain['SeekEnc'] = LabelEncoder().fit_transform(dataframeTrain['Seek'])\n",
    "\n",
    "    # Check if the lead came from high-intent platforms (example: Cars.co.za, Autotrader)\n",
    "    dataframeTrain['HighIntentSource'] = dataframeTrain['LeadSource'].str.contains(\n",
    "    'autotrader|cars|motus|kia|hyundai|autopedigree', case=False, na=False).astype(int)\n",
    "\n",
    "    dataframeTrain['InterestModelEnc'] = LabelEncoder().fit_transform(dataframeTrain['InterestModel'])\n",
    "    dataframeTrain['OBSFullNameEnc'] = LabelEncoder().fit_transform(dataframeTrain['OBSFullName'])\n",
    "    dataframeTrain['OBSEmailEnc'] = LabelEncoder().fit_transform(dataframeTrain['OBSEmail'])\n",
    "    dataframeTrain['CellPrefixEncoded'] = LabelEncoder().fit_transform(dataframeTrain['CellPrefix'])\n",
    "    dataframeTrain['DomainCode'] = LabelEncoder().fit_transform(dataframeTrain['Domain'])\n",
    "\n",
    "    # Converting to datetime\n",
    "    dataframeTrain['DayOfEnquiry'] = pd.to_datetime(dataframeTrain['DayOfEnquiry'])\n",
    "    dataframeTrain['HourOfEnquiry'] = pd.to_datetime(dataframeTrain['HourOfEnquiry'])\n",
    "\n",
    "    # Extracting day of the month (1 to 31) and hour\n",
    "    dataframeTrain['EnquiryDayOfMonth'] = dataframeTrain['DayOfEnquiry'].dt.day\n",
    "    dataframeTrain['TimeHourOfEnquiry'] =  dataframeTrain['HourOfEnquiry'].dt.hour\n",
    "\n",
    "    # Days since first enquiry by this customer\n",
    "    first_enquiry = dataframeTrain.groupby('CustomerID')['DayOfEnquiry'].transform('min')\n",
    "    dataframeTrain['DaysSinceFirstEnquiry'] = (dataframeTrain['DayOfEnquiry'] - first_enquiry).dt.days\n",
    "\n",
    "    X = dataframeTrain[['CustomerID','CustomerIDCount','DealerEnquiryVolume','DTLeadCreatedEnc','DTLeadAllocatedEnc',\n",
    "                        'DealerEnc','DaysSinceFirstEnquiry','LeadSourceEnc','LeadTypeEnc','SeekEnc',\n",
    "                        'InterestModelEnc',\n",
    "                        'CellPrefixEncoded','TimeHourOfEnquiry',\n",
    "                        'EnquiryDayOfMonth','HighIntentSource']]\n",
    "    y = dataframeTrain['VehicleSold']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_under, y_train_under = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    # Balance\n",
    "    negative = sum(y_train == 0)\n",
    "    positive = sum(y_train == 1)\n",
    "    pos_weight = negative / positive if positive > 0 else 1\n",
    "\n",
    "    # Model 2: RandomForest\n",
    "    model_rf = RandomForestClassifier(n_estimators=500, random_state=42, class_weight='balanced')\n",
    "    model_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Random Forest with calibration\n",
    "    cal_rf = CalibratedClassifierCV(model_rf, method='sigmoid', cv=5)\n",
    "    cal_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # 3. Logistic Regression (with scaling)\n",
    "    model_lr = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lr', LogisticRegression(max_iter=1100, class_weight='balanced'))\n",
    "    ])\n",
    "    model_lr.fit(X_train, y_train)\n",
    "\n",
    "    # 4. Gradient Boost\n",
    "    model_gb = GradientBoostingClassifier(n_estimators=500, random_state=42)\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    cal_gb = CalibratedClassifierCV(model_gb, method='sigmoid', cv=5)\n",
    "    cal_gb.fit(X_train, y_train)\n",
    "\n",
    "    # Combine predictions (average)\n",
    "\n",
    "    prob_rf = cal_rf.predict_proba(X_test)[:, 1]\n",
    "    prob_lr = model_lr.predict_proba(X_test)[:, 1]\n",
    "    prob_gb = cal_gb.predict_proba(X_test)[:, 1]\n",
    "    prob_avg = (prob_rf + prob_lr + prob_gb ) / 3\n",
    "\n",
    "\n",
    "    # Evaluate PR-AUC\n",
    "    pr_auc = average_precision_score(y_test, prob_avg)\n",
    "    print(f\"Combined PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    # Compute log loss\n",
    "    logloss_value = log_loss(y_test, prob_avg)\n",
    "    print(f\"Log Loss: {logloss_value:.4f}\")\n",
    "\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, prob_avg)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    best_idx = np.argmax(f1)\n",
    "    best_thresh = thresholds[best_idx]\n",
    "    print(f\"Best threshold (ensemble): {best_thresh:.2f}\")\n",
    "\n",
    "    # Save models and threshold\n",
    "    joblib.dump({'rf': cal_rf,'lr': model_lr, 'cb': cal_gb, 'threshold': best_thresh}, 'mymodel.pkl')\n",
    "\n",
    "    return cal_rf, model_lr, cal_gb, best_thresh\n",
    "\n",
    "\n",
    "def preprocess_data(dataframeTrain):\n",
    "    # Label encodings (same as training)\n",
    "    dataframeTrain['CustomerID'] = LabelEncoder().fit_transform(dataframeTrain['CustomerID'])\n",
    "    dataframeTrain['CustomerIDCount'] = dataframeTrain.groupby('CustomerID')['CustomerID'].transform('count') #Using the count rather than id increases PR-AUC\n",
    "\n",
    "    # Count how many leads a dealer handles (popularity or reach of dealer)\n",
    "    dataframeTrain['DealerEnquiryVolume'] = dataframeTrain.groupby('Dealer')['Dealer'].transform('count')\n",
    "\n",
    "    dataframeTrain['DTLeadCreatedEnc'] = LabelEncoder().fit_transform(dataframeTrain['DTLeadCreated'])\n",
    "    dataframeTrain['DTLeadAllocatedEnc'] = LabelEncoder().fit_transform(dataframeTrain['DTLeadAllocated'])\n",
    "    dataframeTrain['DealerEnc'] = LabelEncoder().fit_transform(dataframeTrain['Dealer'])\n",
    "    dataframeTrain['LeadSourceEnc'] = LabelEncoder().fit_transform(dataframeTrain['LeadSource'])\n",
    "    dataframeTrain['LeadTypeEnc'] = LabelEncoder().fit_transform(dataframeTrain['LeadType'])\n",
    "    dataframeTrain['SeekEnc'] = LabelEncoder().fit_transform(dataframeTrain['Seek'])\n",
    "\n",
    "    # Check if the lead came from high-intent platforms (example: Cars.co.za, Autotrader)\n",
    "    dataframeTrain['HighIntentSource'] = dataframeTrain['LeadSource'].str.contains(\n",
    "    'autotrader|cars|motus|kia|hyundai|autopedigree', case=False, na=False).astype(int)\n",
    "\n",
    "    dataframeTrain['InterestModelEnc'] = LabelEncoder().fit_transform(dataframeTrain['InterestModel'])\n",
    "    dataframeTrain['OBSFullNameEnc'] = LabelEncoder().fit_transform(dataframeTrain['OBSFullName'])\n",
    "    dataframeTrain['OBSEmailEnc'] = LabelEncoder().fit_transform(dataframeTrain['OBSEmail'])\n",
    "    dataframeTrain['CellPrefixEncoded'] = LabelEncoder().fit_transform(dataframeTrain['CellPrefix'])\n",
    "    dataframeTrain['DomainCode'] = LabelEncoder().fit_transform(dataframeTrain['Domain'])\n",
    "\n",
    "\n",
    "    # Converting to datetime\n",
    "    dataframeTrain['DayOfEnquiry'] = pd.to_datetime(dataframeTrain['DayOfEnquiry'])\n",
    "    dataframeTrain['HourOfEnquiry'] = pd.to_datetime(dataframeTrain['HourOfEnquiry'])\n",
    "\n",
    "\n",
    "    # Extracting day of the month (1 to 31) and hour\n",
    "    dataframeTrain['EnquiryDayOfMonth'] = dataframeTrain['DayOfEnquiry'].dt.day\n",
    "    dataframeTrain['TimeHourOfEnquiry'] =  dataframeTrain['HourOfEnquiry'].dt.hour\n",
    "\n",
    "    # Days since first enquiry by this customer\n",
    "    first_enquiry = dataframeTrain.groupby('CustomerID')['DayOfEnquiry'].transform('min')\n",
    "    dataframeTrain['DaysSinceFirstEnquiry'] = (dataframeTrain['DayOfEnquiry'] - first_enquiry).dt.days\n",
    "\n",
    "    # Final feature set\n",
    "    features = dataframeTrain[['CustomerID','CustomerIDCount','DealerEnquiryVolume','DTLeadCreatedEnc','DTLeadAllocatedEnc',\n",
    "                   'DealerEnc','DaysSinceFirstEnquiry','LeadSourceEnc','LeadTypeEnc','SeekEnc',\n",
    "                   'InterestModelEnc',\n",
    "                   'CellPrefixEncoded','TimeHourOfEnquiry',\n",
    "                   'EnquiryDayOfMonth','HighIntentSource']]\n",
    "\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "def predict_from_csv(mymodel, test_csv_path):\n",
    "    URL_TRAIN = \"https://www.mxhackathon.co.za/docs/TrainData.csv\"\n",
    "    URL_TEST = \"https://www.mxhackathon.co.za/docs/TestData.csv\"\n",
    "\n",
    "    df_test_raw = pd.read_csv(URL_TEST)\n",
    "    df_test = df_test_raw.copy()              # Work on a copy\n",
    "\n",
    "    X_test = preprocess_data(df_test)\n",
    "\n",
    "    # Predict probabilities\n",
    "    probabilities = mymodel.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    #thresholding (e.g. 0.8)\n",
    "    threshold = model_dict['threshold']\n",
    "    predictions = (probabilities >= threshold).astype(int)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'LeadID': df_test_raw['LeadID'],  # <-- original values\n",
    "        'VehicleSoldProbability ': (probabilities).round(4)\n",
    "    })\n",
    "    #Sorting the predictions\n",
    "    results_df = results_df.sort_values(by='VehicleSoldProbability ', ascending=False)\n",
    "\n",
    "\n",
    "    # Save to CSV\n",
    "    results_df.to_csv('LeadPredictions.csv', index=False)\n",
    "\n",
    "    print(\"Saved original LeadID and VehicleSoldProbability to 'LeadPredictions.csv'\")\n",
    "\n",
    "\n",
    "def predict_ensemble(model_dict, test_csv_path):\n",
    "    df_raw = pd.read_csv(test_csv_path)\n",
    "    df = df_raw.copy()\n",
    "    X = preprocess_data(df)\n",
    "\n",
    "\n",
    "    prob_rf = model_dict['rf'].predict_proba(X)[:, 1]\n",
    "    prob_lr = model_dict['lr'].predict_proba(X)[:, 1]\n",
    "    prob_gb = model_dict['cb'].predict_proba(X)[:, 1]\n",
    "    prob_avg = (prob_rf + prob_lr + prob_gb) / 3\n",
    "\n",
    "def save_submission(df: pd.DataFrame, prob_avg: pd.Series | np.ndarray):\n",
    "    submission = pd.DataFrame({\n",
    "        \"LeadID\": df[\"LeadID\"],\n",
    "        \"VehicleSoldProbability\": np.round(prob_avg, 4)\n",
    "    }).sort_values(by=\"VehicleSoldProbability\", ascending=False)\n",
    "\n",
    "    submission.to_csv(\"LeadPredictions.csv\", index=False)\n",
    "    print(\"Saved submission to 'LeadPredictions.csv'\")\n",
    "\n",
    "\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "      # Step 1: Load training data\n",
    "    URL_TRAIN = \"https://www.mxhackathon.co.za/docs/TrainData.csv\"\n",
    "    URL_TEST = \"https://www.mxhackathon.co.za/docs/TestData.csv\"\n",
    "    \n",
    "    dfTrain = load_data(URL_TRAIN)  # Required: dfTrain\n",
    "    analyze_missing(dfTrain)\n",
    "    dfTrain = clean_missing_values(dfTrain)\n",
    "\n",
    "    # Step 2: Train the model\n",
    "    cal_rf, model_lr, cal_gb, threshold = train_ensemble_model(dfTrain)\n",
    "\n",
    "    # Step 3: Load test data\n",
    "    dfTest = pd.read_csv(URL_TEST)  # Required: dfTest\n",
    "    X_test = preprocess_data(dfTest)\n",
    "\n",
    "    # Step 4: Predict\n",
    "    model_dict = joblib.load(\"mymodel.pkl\")\n",
    "    prob_rf = model_dict['rf'].predict_proba(X_test)[:, 1]\n",
    "    prob_lr = model_dict['lr'].predict_proba(X_test)[:, 1]\n",
    "    prob_gb = model_dict['cb'].predict_proba(X_test)[:, 1]\n",
    "    probabilities = (prob_rf + prob_lr + prob_gb) / 3\n",
    "\n",
    "    # Step 5: Save submission\n",
    "    save_submission(dfTest, probabilities)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
